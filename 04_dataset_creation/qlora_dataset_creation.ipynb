{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../01_data/aita/AmItheAsshole_submissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize an empty list to store the JSON objects\n",
    "json_objects = []\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "    for i, line in enumerate(file):\n",
    "        # Convert the current line from a JSON string to a JSON object and append it to the list\n",
    "        json_objects.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stories = []\n",
    "for i in json_objects:\n",
    "    smaller_json = {}\n",
    "    if i['score'] > 10 and 'http://www.' not in i['selftext'] and len(i['selftext']) > 25:\n",
    "        smaller_json['id'] = i['id']\n",
    "        smaller_json['title'] = i['title']\n",
    "        smaller_json['selftext'] = i['selftext']\n",
    "        smaller_json['score'] = i['score']\n",
    "        filtered_stories.append(smaller_json)\n",
    "\n",
    "# Sort the filtered stories by score in descending order\n",
    "filtered_stories = sorted(filtered_stories, key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_APIKEY\"),\n",
    ")\n",
    "\n",
    "top_x_stories = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction(story):\n",
    "    # prompt = f\"\"\"\n",
    "    # I am creating an LLM fine tuning dataset in the Alpaca format. I have my desired output stories, and need to create an \"instruction\" for each of them.\n",
    "\n",
    "    # The instruction should be similar to this; \"Write an am I the asshole reddit post about ... story details...\". \n",
    "    \n",
    "    # Please return only the instruction you write.\n",
    "\n",
    "    # Below is the story, please output only a brief instruction set for creating it with an LLM.\n",
    "    \n",
    "    # STORY: {story}\n",
    "    # \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    I am creating a fine-tuning dataset for a large language model (LLM) in the Alpaca format. \n",
    "    Each story in the dataset needs a clear and concise instruction for generating a similar story.\n",
    "\n",
    "    The instruction should guide the LLM to write a story in the style of an \"Am I the Asshole\" Reddit post. \n",
    "    The instruction should include a few details and themes from the story but be brief and to the point.\n",
    "\n",
    "    Please provide only the instruction in your response.\n",
    "\n",
    "    Below is the story. Based on this story, create an appropriate instruction.\n",
    "\n",
    "    STORY: {story}\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a assistant helping to create a high quality dataset for the user.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    instruction = response.choices[0].message.content.strip()\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reddit_post in filtered_stories[:top_x_stories]:\n",
    "    reddit_post['instruction'] = generate_instruction(reddit_post['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Reddit posts saved to post_instruction_data.json\n"
     ]
    }
   ],
   "source": [
    "# Save the modified stories to a new JSON file\n",
    "output_file_path = 'post_instruction_data.json'\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    json.dump(filtered_stories[:top_x_stories], outfile, indent=4)\n",
    "\n",
    "print(f\"Modified Reddit posts saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
